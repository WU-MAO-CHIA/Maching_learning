{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pytorch Tutorial","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOdDj1+/1vpZI8yLTvG6SVo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"mPh5lD_z2qrD","executionInfo":{"status":"ok","timestamp":1642487074740,"user_tz":-480,"elapsed":6329,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"outputs":[],"source":["import torch"]},{"cell_type":"code","source":["x = torch.randn(4, 5)\n","y = torch.randn(4, 5)\n","z = torch.randn(4, 5)\n","\n","print(x)\n","print(y)\n","print(z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bpYgL6By3tIW","executionInfo":{"status":"ok","timestamp":1642487341829,"user_tz":-480,"elapsed":496,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"5dd51885-588a-442a-95a6-0ebed3567714"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.4869, -0.4797, -2.3133, -0.9358,  0.4817],\n","        [-0.2434, -0.8296, -2.5100, -1.1842, -0.3759],\n","        [-1.1343, -0.3111,  0.1249, -0.6124, -0.5587],\n","        [ 0.7137,  0.7476,  1.5078,  0.7107,  0.3675]])\n","tensor([[-0.2900,  0.3320,  1.0073,  0.2451, -1.3584],\n","        [-0.6834,  0.5139,  0.6868, -0.9722, -1.7343],\n","        [-0.5984, -0.1844, -0.0440,  1.4624, -0.4606],\n","        [ 0.8162,  1.6790, -0.3628,  0.8674,  0.0680]])\n","tensor([[-0.1763, -0.4940, -1.0130, -0.9775, -0.3783],\n","        [-0.0380,  0.7094, -0.6735,  1.3980, -1.9120],\n","        [ 1.4891, -1.0546,  2.1346, -0.5079,  1.5897],\n","        [-0.1844, -0.8030, -1.3127, -0.4724,  1.0374]])\n"]}]},{"cell_type":"code","source":["# torch.max(x) find the biggest in the x\n","m = torch.max(x)\n","print(m)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tOqJskrY4ATx","executionInfo":{"status":"ok","timestamp":1642487375614,"user_tz":-480,"elapsed":858,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"f46cdad9-d288-44f3-971d-0cc056b7e11d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.5078)\n"]}]},{"cell_type":"code","source":["# dim= 0 is 行 1 is 列 idx is 第幾個\n","m, idx = torch.max(x, 0)\n","print(m)\n","print(idx)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7u6_70Em4AHO","executionInfo":{"status":"ok","timestamp":1642487530982,"user_tz":-480,"elapsed":417,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"a791a581-4dd2-4b2e-d8dd-756d7bbc6f29"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 0.4869, -0.2434,  0.1249,  1.5078])\n","tensor([0, 0, 2, 2])\n"]}]},{"cell_type":"code","source":["m, idx = torch.max(input= x, dim= 0)\n","print(m)\n","print(idx)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N9BZ_XPf48Px","executionInfo":{"status":"ok","timestamp":1642487637468,"user_tz":-480,"elapsed":651,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"0d686765-a668-480f-8dbe-0bcf30577997"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.7137, 0.7476, 1.5078, 0.7107, 0.4817])\n","tensor([3, 3, 3, 3, 0])\n"]}]},{"cell_type":"code","source":["m, idx = torch.max(x, 0, False)\n","print(m)\n","print(idx)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AiW6uWXD5HCP","executionInfo":{"status":"ok","timestamp":1642487673821,"user_tz":-480,"elapsed":814,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"fb24056d-66ed-430e-865f-9cdebc9629f7"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.7137, 0.7476, 1.5078, 0.7107, 0.4817])\n","tensor([3, 3, 3, 3, 0])\n"]}]},{"cell_type":"code","source":["# keepdim 維持原本tensor的dim\n","m, idx = torch.max(x, 0, keepdim= True)\n","print(m)\n","print(idx)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vwtpRTAp5Qhn","executionInfo":{"status":"ok","timestamp":1642487736823,"user_tz":-480,"elapsed":803,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"7efe5eff-4e3a-43e5-d7ba-f756d08ba176"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.7137, 0.7476, 1.5078, 0.7107, 0.4817]])\n","tensor([[3, 3, 3, 3, 0]])\n"]}]},{"cell_type":"code","source":["p = (m, idx)\n","torch.max(x, 0, False, out= p)\n","print(p[0])\n","print(p[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C1lJOLyO5neu","executionInfo":{"status":"ok","timestamp":1642487825491,"user_tz":-480,"elapsed":1146,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"a7740b01-9451-4b3a-f3c8-6ed7dd06ecb9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.7137, 0.7476, 1.5078, 0.7107, 0.4817])\n","tensor([3, 3, 3, 3, 0])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 5], which does not match the required output shape [1, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n","  \n"]}]},{"cell_type":"code","source":["m, idx = torch.max(x,True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"ui-vJ07-56l5","executionInfo":{"status":"error","timestamp":1642487981619,"user_tz":-480,"elapsed":1458,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"9484c01b-fdb6-4b0c-c5f6-3fcca7133722"},"execution_count":17,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-c7336a03f7be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (Tensor, bool), but expected one of:\n * (Tensor input)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n"]}]},{"cell_type":"code","source":["model = torch.nn.Linear(5, 1).to('cuda:0')\n","x = torch.Tensor([1, 2, 3, 4, 5]).to('cpu')\n","y = model(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"id":"b7Y1pGkD6baP","executionInfo":{"status":"error","timestamp":1642488174898,"user_tz":-480,"elapsed":9251,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"635c73ad-7c4f-449b-e4e8-bb997521a66f"},"execution_count":19,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-ce16caf70c80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_mm)"]}]},{"cell_type":"code","source":["x = torch.Tensor([1, 2, 3, 4, 5]).to('cuda:0')\n","y = model(x)\n","print(y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FzoaG4q-7MjU","executionInfo":{"status":"ok","timestamp":1642488264362,"user_tz":-480,"elapsed":4,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"881f4c27-49e9-4546-ee77-9502e3f55696"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1])\n"]}]},{"cell_type":"code","source":["x = torch.randn(4, 5)\n","y = torch.randn(5, 4)\n","z = x + y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":218},"id":"ofNx5haO7hHh","executionInfo":{"status":"error","timestamp":1642488473103,"user_tz":-480,"elapsed":400,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"ef46570b-ee89-4b9b-8e85-4656f64837e1"},"execution_count":27,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-5408ca40d128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"]}]},{"cell_type":"code","source":["y = y.transpose(0, 1)\n","z = x + y\n","print(y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"188NAScL7-GY","executionInfo":{"status":"ok","timestamp":1642488538583,"user_tz":-480,"elapsed":424,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"b2afe83c-812d-4aaf-f793-3d2e96f0733d"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 5])\n"]}]},{"cell_type":"code","source":["import torchvision.models as models\n","resnet18 = models.resnet18().to('cuda:0')\n","data = torch.randn(2048, 3, 244, 244)\n","out = resnet18(data.to('cuda:0'))\n","print(out.shape) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":468},"id":"1NaXA-rY8keN","executionInfo":{"status":"error","timestamp":1642488727053,"user_tz":-480,"elapsed":8342,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"6fed1176-1118-4818-917c-b0cdc5210888"},"execution_count":38,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-4b414a10219b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresnet18\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m244\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m244\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2283\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2284\u001b[0m     )\n\u001b[1;32m   2285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 7.27 GiB (GPU 0; 11.17 GiB total capacity; 8.72 GiB already allocated; 1.91 GiB free; 8.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["for d in data:\n","  out = resnet18(d.to('cuda:0').unsqueeze(0))\n","print(out.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NjmiHM_u9ZRM","executionInfo":{"status":"ok","timestamp":1642488905101,"user_tz":-480,"elapsed":86447,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"61f44f9b-1848-440a-8c00-eb0bb9177cf2"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 1000])\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","L = nn.CrossEntropyLoss()\n","outs = torch.randn(5, 5)\n","labels = torch.Tensor([1, 2, 3, 4, 0])\n","lossval = L(outs, labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"w1YwaqJk9a5d","executionInfo":{"status":"error","timestamp":1642488974661,"user_tz":-480,"elapsed":476,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"c94173ed-be36-48e4-fd0f-59f29feb8af5"},"execution_count":41,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-8bf67766db6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlossval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"]}]},{"cell_type":"code","source":["labels = labels.long()\n","lossval = L(outs, labels)\n","print(lossval)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UOCeenWB-cIv","executionInfo":{"status":"ok","timestamp":1642489086431,"user_tz":-480,"elapsed":463,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"de387eca-ce90-446f-c75f-3b75db6b6565"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.3034)\n"]}]},{"cell_type":"code","source":["dataset = \"abcdefghijklmnopqrstuvwxyz\""],"metadata":{"id":"Hwhr06U_-t_L","executionInfo":{"status":"ok","timestamp":1642489113198,"user_tz":-480,"elapsed":823,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["for datapoint in dataset:\n","  print(datapoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jmc9HnkB-vLU","executionInfo":{"status":"ok","timestamp":1642489144845,"user_tz":-480,"elapsed":655,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"7e9c6494-c303-4741-fa76-2134d255513b"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["a\n","b\n","c\n","d\n","e\n","f\n","g\n","h\n","i\n","j\n","k\n","l\n","m\n","n\n","o\n","p\n","q\n","r\n","s\n","t\n","u\n","v\n","w\n","x\n","y\n","z\n"]}]},{"cell_type":"code","source":["import torch.utils.data\n","class ExampleDataset(torch.utils.data.Dataset):\n","  def __init__(self):\n","    self.data = \"abcdefghijklmnopqrstuvwxyz\"\n","\n","  def __getitem__(self, idx):\n","    return self.data[idx]\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","dataset1 = ExampleDataset()       \n","dataloader = torch.utils.data.DataLoader(dataset= dataset1, shuffle = True, batch_size = 1)\n","for datapoint in dataloader:\n","  print(datapoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sODSaST8_LCX","executionInfo":{"status":"ok","timestamp":1642489745259,"user_tz":-480,"elapsed":865,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"316a80a3-1ed4-4ba3-8de2-1ccf0e46e10a"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["['b']\n","['a']\n","['v']\n","['l']\n","['q']\n","['k']\n","['s']\n","['u']\n","['o']\n","['m']\n","['h']\n","['i']\n","['c']\n","['r']\n","['n']\n","['t']\n","['y']\n","['w']\n","['d']\n","['p']\n","['f']\n","['z']\n","['j']\n","['x']\n","['e']\n","['g']\n"]}]},{"cell_type":"code","source":["import torch.utils.data\n","class ExampleDataset(torch.utils.data.Dataset):\n","  def __init__(self):\n","    self.data = 'abcdefghijklmnopqrstuvwxyz'\n","\n","  def __getitem__(self, idx):\n","    if idx >= len(self.data):\n","      return self.data[idx%26].upper()\n","    else:\n","      return self.data[idx]\n","\n","  def __len__(self):\n","      return 2 * len(self.data)\n","\n","dataset1 = ExampleDataset()\n","dataloader = torch.utils.data.DataLoader(dataset = dataset1, shuffle = True, batch_size = 1)\n","for datapoint in dataloader:\n","  print(datapoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7e6CMhnhBDDs","executionInfo":{"status":"ok","timestamp":1642490064267,"user_tz":-480,"elapsed":743,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"3df64452-edba-4c34-c343-9720aa80f3ce"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["['B']\n","['f']\n","['t']\n","['s']\n","['l']\n","['A']\n","['r']\n","['g']\n","['S']\n","['p']\n","['h']\n","['Z']\n","['K']\n","['n']\n","['k']\n","['i']\n","['v']\n","['w']\n","['H']\n","['e']\n","['D']\n","['O']\n","['G']\n","['C']\n","['x']\n","['c']\n","['z']\n","['m']\n","['U']\n","['E']\n","['F']\n","['b']\n","['T']\n","['X']\n","['J']\n","['j']\n","['P']\n","['Q']\n","['y']\n","['M']\n","['a']\n","['L']\n","['Y']\n","['o']\n","['u']\n","['I']\n","['V']\n","['R']\n","['q']\n","['W']\n","['N']\n","['d']\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"tYuasNsEBcrR"},"execution_count":null,"outputs":[]}]}