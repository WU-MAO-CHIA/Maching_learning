{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW5","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1de96091c38f4b259a77d8a119161920":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_860ed7d6da024eb1a413321a3e025642","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_585e4b1c43224f33ba022b0fe3873fda","IPY_MODEL_c8d6641edc25417396006ff4c963c823","IPY_MODEL_e1bc046b06e14f1ea7381be6669a6fc4"]}},"860ed7d6da024eb1a413321a3e025642":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"585e4b1c43224f33ba022b0fe3873fda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_aa69470e3eb341ab88a0055953ff54a5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"train epoch 1: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_179945ff35274a57bd7d09f12aeaff06"}},"c8d6641edc25417396006ff4c963c823":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_329c729bfebc4fd0abb297329498f2ea","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":787,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":787,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_698e893fce3048869a6afa576826bbe8"}},"e1bc046b06e14f1ea7381be6669a6fc4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_93dd6a019c0a48a98ac3ef1440a298f0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 787/787 [15:47&lt;00:00,  1.16s/it, loss=6.76]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8cda8aa7f47c4745a0b4ff720d8d0e31"}},"aa69470e3eb341ab88a0055953ff54a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"179945ff35274a57bd7d09f12aeaff06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"329c729bfebc4fd0abb297329498f2ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"698e893fce3048869a6afa576826bbe8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"93dd6a019c0a48a98ac3ef1440a298f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8cda8aa7f47c4745a0b4ff720d8d0e31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"490efaddc7454c2eaf962836635eac1e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6be68187e89247b8a18d8d17032f7f08","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_34afd702f70c4ad68d0b28490e9586ed","IPY_MODEL_9219aaaa7f8e4065a356028d56c2ff0e","IPY_MODEL_bc1f81fed1064b719a28572973208c0d"]}},"6be68187e89247b8a18d8d17032f7f08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"34afd702f70c4ad68d0b28490e9586ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b55c5935ce4145c88df3ceda73543fc3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"validation:   0%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_479a66174c4142b49563e049dc7d4a37"}},"9219aaaa7f8e4065a356028d56c2ff0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_51b03c066cbc433bae18e57184b1d1e8","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":22,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6e0f18d280bf48de9daccec572927023"}},"bc1f81fed1064b719a28572973208c0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_60debec359a24cbca32799ed6a935269","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/22 [00:00&lt;?, ?it/s, valid_loss=6.9]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a86407264aff4821a3ba11475e93ad9b"}},"b55c5935ce4145c88df3ceda73543fc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"479a66174c4142b49563e049dc7d4a37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51b03c066cbc433bae18e57184b1d1e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6e0f18d280bf48de9daccec572927023":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"60debec359a24cbca32799ed6a935269":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a86407264aff4821a3ba11475e93ad9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","source":["!pip install 'torch>=1.6.0' editdistance matplotlib sacrebleu sacremoses sentencepiece tqdm wandb\n","!pip install --upgrade jupyter ipywidgets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XdcmsmiHJCWu","executionInfo":{"status":"ok","timestamp":1644237041769,"user_tz":-480,"elapsed":20899,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"d3485d0e-10ec-4425-e9a9-d23d6ab6d4ff"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (0.5.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 3.9 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 31.6 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 26.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n","Collecting wandb\n","  Downloading wandb-0.12.10-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 35.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0) (3.10.0.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.8.9)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (2019.12.20)\n","Collecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.4-py2.py3-none-any.whl (143 kB)\n","\u001b[K     |████████████████████████████████| 143 kB 35.9 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 33.9 MB/s \n","\u001b[?25hCollecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 702 kB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=462d34ef0a1cd7b86b181457d0df7745c7dd2d661173adb6826323724105c7f7\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, yaspin, shortuuid, sentry-sdk, portalocker, pathtools, GitPython, docker-pycreds, colorama, wandb, sentencepiece, sacremoses, sacrebleu\n","Successfully installed GitPython-3.1.26 colorama-0.4.4 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 portalocker-2.3.2 sacrebleu-2.0.0 sacremoses-0.0.47 sentencepiece-0.1.96 sentry-sdk-1.5.4 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.10 yaspin-2.1.0\n","Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (1.0.0)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (7.6.5)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.2.2)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.2.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.6.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter) (4.10.1)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.3.1)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (0.2.0)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.5.2)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.3)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (1.0.2)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.5.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.1)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter) (5.1.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter) (5.3.5)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.8.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (1.0.18)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.3.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.9.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.4.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (5.4.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.10.0.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (4.10.1)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (1.15.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter) (0.13.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter) (1.8.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter) (2.11.3)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter) (22.3.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter) (2.8.2)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter) (2.0.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.4)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.5.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.7.1)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (1.5.0)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (4.1.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.8.4)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter) (0.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->jupyter) (3.0.7)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter) (2.0.1)\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/pytorch/fairseq.git\n","!cd fairseq && git checkout 9a1c497\n","!pip install --upgrade ./fairseq/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JYrpJrcLTWq6","executionInfo":{"status":"ok","timestamp":1644237176060,"user_tz":-480,"elapsed":75997,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"038aa923-ecc7-4a09-e6fe-be10a60e86b5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'fairseq'...\n","remote: Enumerating objects: 30845, done.\u001b[K\n","remote: Counting objects: 100% (477/477), done.\u001b[K\n","remote: Compressing objects: 100% (291/291), done.\u001b[K\n","remote: Total 30845 (delta 197), reused 371 (delta 179), pack-reused 30368\u001b[K\n","Receiving objects: 100% (30845/30845), 21.20 MiB | 24.44 MiB/s, done.\n","Resolving deltas: 100% (22895/22895), done.\n","Note: checking out '9a1c497'.\n","\n","You are in 'detached HEAD' state. You can look around, make experimental\n","changes and commit them, and you can discard any commits you make in this\n","state without impacting any branches by performing another checkout.\n","\n","If you want to create a new branch to retain commits you create, you may\n","do so (now or later) by using -b with the checkout command again. Example:\n","\n","  git checkout -b <new-branch-name>\n","\n","HEAD is now at 9a1c4970 Make Hydra logging work with DDP (#1568)\n","Processing ./fairseq\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting omegaconf<2.1\n","  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+9a1c497) (1.15.0)\n","Collecting hydra-core<1.1\n","  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n","\u001b[K     |████████████████████████████████| 123 kB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+9a1c497) (1.19.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+9a1c497) (2019.12.20)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+9a1c497) (4.62.3)\n","Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+9a1c497) (2.0.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+9a1c497) (1.10.0+cu111)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+9a1c497) (0.29.27)\n","Collecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 43.4 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1->fairseq==1.0.0a0+9a1c497) (5.4.0)\n","Collecting PyYAML>=5.1.*\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 44.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+9a1c497) (3.10.0.2)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+9a1c497) (2.3.2)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+9a1c497) (0.8.9)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+9a1c497) (0.4.4)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+9a1c497) (2.21)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core<1.1->fairseq==1.0.0a0+9a1c497) (3.7.0)\n","Building wheels for collected packages: fairseq, antlr4-python3-runtime\n","  Building wheel for fairseq (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairseq: filename=fairseq-1.0.0a0+9a1c497-cp37-cp37m-linux_x86_64.whl size=2863608 sha256=0abd7e2b9fde3c898d19ccee042948ce25aa64908374f080d7fd8ebed26c035e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-q0wj0nsq/wheels/7c/35/80/edbd520a1a7e615df007002aeea9f6bf5f3c8f9243e072f6ce\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=d23a3f33f3de60b9d0d7d355572e35340c459992c2a58306d459f648d9dba35b\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","Successfully built fairseq antlr4-python3-runtime\n","Installing collected packages: PyYAML, omegaconf, antlr4-python3-runtime, hydra-core, fairseq\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 fairseq-1.0.0a0+9a1c497 hydra-core-1.0.7 omegaconf-2.0.6\n"]}]},{"cell_type":"code","source":["import sys\n","import pdb\n","import pprint\n","import logging\n","import os\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils import data\n","import numpy as np\n","import tqdm.auto as tqdm\n","from pathlib import Path\n","from argparse import Namespace\n","from fairseq import utils\n","\n","import matplotlib.pyplot as plt"],"metadata":{"id":"1YFsoudzTdTT","executionInfo":{"status":"ok","timestamp":1644237179589,"user_tz":-480,"elapsed":1876,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["seed = 73\n","random.seed(seed)\n","torch.manual_seed(seed)\n","if torch.cuda.is_available():\n","  torch.cuda.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True"],"metadata":{"id":"bp42-TvdUHcR","executionInfo":{"status":"ok","timestamp":1644237184975,"user_tz":-480,"elapsed":234,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!apt-get install megatools"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BsppiACpMRTf","executionInfo":{"status":"ok","timestamp":1644237198946,"user_tz":-480,"elapsed":10651,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"b4dba13d-2663-42c0-917c-b84078373df5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following packages were automatically installed and are no longer required:\n","  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n","  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n","  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n","  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n","  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n","  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n","  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n","  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n","  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n","  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n","  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n","  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n","  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n","  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n","  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n","  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n","  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n","  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n","  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n","  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n","  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n","  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n","  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n","  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n","  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n","  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n","  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n","  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n","  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n","  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n","  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n","  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n","  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n","  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n","  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n","Use 'apt autoremove' to remove them.\n","The following NEW packages will be installed:\n","  megatools\n","0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n","Need to get 148 kB of archives.\n","After this operation, 1,097 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 megatools amd64 1.9.98-1build2 [148 kB]\n","Fetched 148 kB in 1s (227 kB/s)\n","Selecting previously unselected package megatools.\n","(Reading database ... 155113 files and directories currently installed.)\n","Preparing to unpack .../megatools_1.9.98-1build2_amd64.deb ...\n","Unpacking megatools (1.9.98-1build2) ...\n","Setting up megatools (1.9.98-1build2) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"]}]},{"cell_type":"code","source":["data_dir = './DATA/rawdata'\n","dataset_name = 'ted2020'\n","urls = (\n","#    '\"https://onedrive.live.com/download?cid=3E549F3B24B238B4&resid=3E549F3B24B238B4%214989&authkey=AGgQ-DaR8eFSl1A\"', \n","#    '\"https://onedrive.live.com/download?cid=3E549F3B24B238B4&resid=3E549F3B24B238B4%214987&authkey=AA4qP_azsicwZZM\"',\n","     \"https://mega.nz/#!vEcTCISJ!3Rw0eHTZWPpdHBTbQEqBDikDEdFPr7fI8WxaXK9yZ9U\",\n","     \"https://mega.nz/#!zNcnGIoJ!oPJX9AvVVs11jc0SaK6vxP_lFUNTkEcK2WbxJpvjU5Y\",\n","      )\n","file_names = (\n","    'ted2020.tgz',\n","    'test.tgz',\n",")\n","prefix = Path(data_dir).absolute() / dataset_name\n","\n","prefix.mkdir(parents= True, exist_ok= True)\n","for u, f in zip(urls, file_names):\n","  path = prefix/f\n","  if not path.exists():\n","    if 'mega' in u:\n","      !megadl {u} --path {path}\n","    else:\n","      !wget {u} -O {path}\n","  if path.suffix =='.tgz':\n","    !tar -xvf {path} -C {prefix}\n","  elif path.suffix == '.zip':\n","    !unzip -o {path} -d {prefix}\n","!mv {prefix/ 'raw.en'} {prefix/'train_dev.raw.en'}\n","!mv {prefix/ 'raw.zh'} {prefix/'train_dev.raw.zh'}\n","!mv {prefix/ 'test.en'} {prefix/'test.raw.en'}\n","!mv {prefix/ 'test.zh'} {prefix/'test.raw.zh'}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fmxpxPlUUw5O","executionInfo":{"status":"ok","timestamp":1644237217617,"user_tz":-480,"elapsed":14384,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"8c583b87-c031-442a-f0c2-65049b067372"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0KDownloaded ted2020.tgz\n","raw.en\n","raw.zh\n","\u001b[0KDownloaded test.tgz\n","test.en\n","test.zh\n"]}]},{"cell_type":"code","source":["src_lang = 'en'\n","tgt_lang = 'zh'\n","\n","data_prefix = f'{prefix}/train_dev.raw'\n","test_prefix = f'{prefix}/test.raw'"],"metadata":{"id":"jrYsVTXXCPkh","executionInfo":{"status":"ok","timestamp":1644237222269,"user_tz":-480,"elapsed":217,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["!head {data_prefix+ '.'+ src_lang} -n 5\n","!head {data_prefix+ '.'+ tgt_lang} -n 5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NNcrYHULCkn2","executionInfo":{"status":"ok","timestamp":1644237224608,"user_tz":-480,"elapsed":621,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"c8ae46c8-e040-45d1-874e-4e26572d5da6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Thank you so much, Chris.\n","And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\n","I have been blown away by this conference, and I want to thank all of you for the many nice comments about what I had to say the other night.\n","And I say that sincerely, partly because  I need that.\n","Put yourselves in my position.\n","非常謝謝你，克里斯。能有這個機會第二度踏上這個演講台\n","真是一大榮幸。我非常感激。\n","這個研討會給我留下了極為深刻的印象，我想感謝大家 對我之前演講的好評。\n","我是由衷的想這麼說，有部份原因是因為 —— 我真的有需要!\n","請你們設身處地為我想一想！\n"]}]},{"cell_type":"code","source":["import re\n","\n","def strQ2B(ustring):\n","  ss = []\n","  for s in ustring:\n","    rstring = ''\n","    for uchar in s:\n","      inside_code = ord(uchar)\n","      if inside_code == 12288:\n","        inside_code = 32\n","      elif (inside_code >= 65281 and inside_code <= 65374):\n","        inside_code -= 65248\n","      rstring += chr(inside_code)\n","    ss.append(rstring)\n","  return ''.join(ss)\n","\n","def clean_s(s, lang):\n","  if lang == 'en':\n","    s = re.sub(r\"\\([^()]*\\)\", \"\", s)\n","    s = s.replace('-', '')\n","    s = re.sub('([.,;!?()\\\"])', r' \\1 ', s)\n","  elif lang == 'zh': \n","    s = strQ2B(s)\n","    s = re.sub(r'\\([^()]*\\)', '', s)\n","    s = s.replace(' ', '')\n","    s = s.replace('—', '')\n","    s = s.replace('“', '\"')\n","    s = s.replace('”', '\"')\n","    s = s.replace('_', '')\n","    s = re.sub('([。,;!?()\\\"~「」])', r' \\1', s)\n","  s = ' '.join(s.strip().split())\n","  return s\n","\n","def len_s(s, lang):\n","  if lang == 'zh':\n","    return len(s)\n","  return len(s.split())\n","\n","def clean_corpus(prefix, l1, l2, ratio= 9, max_len= 1000, min_len= 1):\n","  if Path(f'{prefix}.clean.{l1}').exists() and Path(f'{prefix}.clean.{l2}').exists():\n","    print(f'{prefix}.clean.{l1} & {l2} exists. skipping clean.')\n","    return\n","  with open(f'{prefix}.{l1}', 'r') as l1_in_f:\n","    with open(f'{prefix}.{l2}', 'r') as l2_in_f:\n","      with open(f'{prefix}.clean.{l1}', 'w') as l1_out_f:\n","        with open(f'{prefix}.clean.{l2}', 'w') as l2_out_f:\n","          for s1 in l1_in_f:\n","            s1 = s1.strip()\n","            s2 = l2_in_f.readline().strip()\n","            s1 = clean_s(s1, l1)\n","            s2 = clean_s(s2, l2)\n","            s1_len = len_s(s1, l1)\n","            s2_len = len_s(s2, l2)\n","            if min_len > 0:\n","              if s1_len < min_len or s2_len < min_len:\n","                continue\n","            if max_len > 0:\n","              if s1_len > max_len or s2_len > max_len:\n","                continue\n","            if ratio > 0:\n","              if s1_len/s2_len > ratio or s2_len/s1_len > ratio:\n","                continue\n","            print(s1, file= l1_out_f)\n","            print(s2, file= l2_out_f)"],"metadata":{"id":"fRSWSJPsCz6o","executionInfo":{"status":"ok","timestamp":1644237225575,"user_tz":-480,"elapsed":1,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["clean_corpus(data_prefix, src_lang, tgt_lang)\n","clean_corpus(test_prefix, src_lang, tgt_lang, ratio= -1, min_len= -1, max_len= -1)"],"metadata":{"id":"wPL5B8bKHpxv","executionInfo":{"status":"ok","timestamp":1644237267148,"user_tz":-480,"elapsed":39883,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["!head {data_prefix+ '.clean.' + src_lang} -n 5\n","!head {data_prefix+ '.clean.' + tgt_lang} -n 5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sVlK22KVORr7","executionInfo":{"status":"ok","timestamp":1644237276139,"user_tz":-480,"elapsed":675,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"75a4c125-9297-48ec-da2c-8aa0f4508c79"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Thank you so much , Chris .\n","And it's truly a great honor to have the opportunity to come to this stage twice ; I'm extremely grateful .\n","I have been blown away by this conference , and I want to thank all of you for the many nice comments about what I had to say the other night .\n","And I say that sincerely , partly because I need that .\n","Put yourselves in my position .\n","非常謝謝你 ,克里斯 。能有這個機會第二度踏上這個演講台\n","真是一大榮幸 。我非常感激 。\n","這個研討會給我留下了極為深刻的印象 ,我想感謝大家對我之前演講的好評 。\n","我是由衷的想這麼說 ,有部份原因是因為我真的有需要 !\n","請你們設身處地為我想一想 !\n"]}]},{"cell_type":"code","source":["valid_ratio = 0.01\n","train_ratio = 1 - valid_ratio"],"metadata":{"id":"FnEoe4NcP7zo","executionInfo":{"status":"ok","timestamp":1644237276776,"user_tz":-480,"elapsed":2,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["if (prefix/f'train.clean.{src_lang}').exists() \\\n","and (prefix/f'train.clean.{tgt_lang}').exists() \\\n","and (prefix/f'valid.clean.{src_lang}').exists() \\\n","and (prefix/f'valid.clean.{tgt_lang}').exists():\n","  print(f'train/valid splits exists. skipping split.')\n","else:\n","  line_num = sum(1 for line in open(f'{data_prefix}.clean.{src_lang}'))\n","  labels = list(range(line_num))\n","  random.shuffle(labels)\n","  for lang in [src_lang, tgt_lang]:\n","    train_f = open(os.path.join(data_dir, dataset_name, f'train.clean.{lang}'), 'w')\n","    valid_f = open(os.path.join(data_dir, dataset_name, f'valid.clean.{lang}'), 'w')\n","    count = 0\n","    for line in open(f'{data_prefix}.clean.{lang}', 'r'):\n","      if labels[count]/line_num < train_ratio:\n","        train_f.write(line)\n","      else:\n","        valid_f.write(line)\n","      count += 1\n","    train_f.close()\n","    valid_f.close()"],"metadata":{"id":"yOsHXUslQCPP","executionInfo":{"status":"ok","timestamp":1644237280719,"user_tz":-480,"elapsed":2872,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import sentencepiece as spm\n","vocab_size = 8000\n","if (prefix/f'spm{vocab_size}.model').exists():\n","    print(f'{prefix}/spm{vocab_size}.model exists. skipping spm_train.')\n","else:\n","    spm.SentencePieceTrainer.train(\n","        input=','.join([f'{prefix}/train.clean.{src_lang}',\n","                        f'{prefix}/valid.clean.{src_lang}',\n","                        f'{prefix}/train.clean.{tgt_lang}',\n","                        f'{prefix}/valid.clean.{tgt_lang}']),\n","        model_prefix=prefix/f'spm{vocab_size}',\n","        vocab_size=vocab_size,\n","        character_coverage=1,\n","        model_type='unigram', \n","        input_sentence_size=1e6,\n","        shuffle_input_sentence=True,\n","        normalization_rule_name='nmt_nfkc_cf',\n","    )"],"metadata":{"id":"jYWlq5sPHQ-e","executionInfo":{"status":"ok","timestamp":1644237668297,"user_tz":-480,"elapsed":385049,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["spm_model = spm.SentencePieceProcessor(model_file=str(prefix/f'spm{vocab_size}.model'))\n","in_tag = {\n","          'train': 'train.clean',\n","          'valid': 'valid.clean',\n","          'test': 'test.raw.clean',\n","         }\n","for split in ['train', 'valid', 'test']:\n","  for lang in [src_lang, tgt_lang]:\n","    out_path = prefix/f'{split}.{lang}'\n","    if out_path.exists():\n","      print(f'{out_path} exists. skipping spm_encode.')\n","    else:\n","      with open(prefix/f'{split}.{lang}', 'w') as out_f:\n","        with open(prefix/f'{in_tag[split]}.{lang}', 'r') as in_f:\n","          for line in in_f:\n","            line = line.strip()\n","            tok = spm_model.encode(line, out_type= str)\n","            print(' '.join(tok), file= out_f)"],"metadata":{"id":"2ETI7sL-FKgx","executionInfo":{"status":"ok","timestamp":1644237718798,"user_tz":-480,"elapsed":48053,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["!head {data_dir+ '/'+ dataset_name+ '/train.'+ src_lang} -n 5\n","!head {data_dir+ '/'+ dataset_name+ '/train.'+ tgt_lang} -n 5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Yv5eJdNGp0I","executionInfo":{"status":"ok","timestamp":1644237768617,"user_tz":-480,"elapsed":786,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"dfc2d2c1-038d-4c40-cbee-9db7c53257b5"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["▁thank ▁you ▁so ▁much ▁, ▁chris ▁.\n","▁and ▁it ' s ▁tr u ly ▁a ▁great ▁ho n or ▁to ▁have ▁the ▁ op port un ity ▁to ▁come ▁to ▁this ▁st age ▁ t wi ce ▁; ▁i ' m ▁ex t re me ly ▁gr ate ful ▁.\n","▁i ▁have ▁been ▁b l ow n ▁away ▁by ▁this ▁con fer ence ▁, ▁and ▁i ▁want ▁to ▁thank ▁all ▁of ▁you ▁for ▁the ▁many ▁ ni ce ▁com ment s ▁about ▁what ▁i ▁had ▁to ▁say ▁the ▁other ▁night ▁.\n","▁and ▁i ▁say ▁that ▁since re ly ▁, ▁part ly ▁because ▁i ▁need ▁that ▁.\n","▁put ▁your s el ve s ▁in ▁my ▁po s ition ▁.\n","▁ 非常 謝謝 你 ▁, 克 里 斯 ▁。 能 有 這個 機會 第二 度 踏 上 這個 演講 台\n","▁ 真 是 一 大 榮 幸 ▁。 我 非常 感 激 ▁。\n","▁這個 研 討 會 給我 留 下 了 極 為 深 刻 的 印 象 ▁, 我想 感 謝 大家 對 我 之前 演講 的 好 評 ▁。\n","▁我 是由 衷 的 想 這麼 說 ▁, 有 部份 原因 是因為 我 真的 有 需要 ▁!\n","▁ 請 你們 設 身 處 地 為 我想 一 想 ▁!\n"]}]},{"cell_type":"code","source":["binpath = Path('./DATA/data-bin', dataset_name)\n","if binpath.exists():\n","  print(binpath, 'exists, will not overwrite!')\n","else:\n","  !python -m fairseq_cli.preprocess \\\n","    --source-lang {src_lang}\\\n","    --target-lang {tgt_lang}\\\n","    --trainpref {prefix/'train'}\\\n","    --validpref {prefix/'valid'}\\\n","    --testpref {prefix/'test'}\\\n","    --destdir {binpath}\\\n","    --joined-dictionary\\\n","    --workers 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ONMg66REJArc","executionInfo":{"status":"ok","timestamp":1644238050445,"user_tz":-480,"elapsed":280596,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"b06d9839-048f-4c23-ccb2-bad792c5f36e"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-02-07 12:42:54 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='DATA/data-bin/ted2020', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='en', srcdict=None, suppress_crashes=False, target_lang='zh', task='translation', tensorboard_logdir=None, testpref='/content/DATA/rawdata/ted2020/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/content/DATA/rawdata/ted2020/train', user_dir=None, validpref='/content/DATA/rawdata/ted2020/valid', wandb_project=None, workers=2)\n","2022-02-07 12:44:59 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8000 types\n","2022-02-07 12:46:17 | INFO | fairseq_cli.preprocess | [en] /content/DATA/rawdata/ted2020/train.en: 390062 sents, 12186806 tokens, 0.0% replaced by <unk>\n","2022-02-07 12:46:17 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8000 types\n","2022-02-07 12:46:18 | INFO | fairseq_cli.preprocess | [en] /content/DATA/rawdata/ted2020/valid.en: 3940 sents, 121460 tokens, 0.0% replaced by <unk>\n","2022-02-07 12:46:18 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8000 types\n","2022-02-07 12:46:19 | INFO | fairseq_cli.preprocess | [en] /content/DATA/rawdata/ted2020/test.en: 4000 sents, 122541 tokens, 0.0% replaced by <unk>\n","2022-02-07 12:46:19 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 8000 types\n","2022-02-07 12:47:28 | INFO | fairseq_cli.preprocess | [zh] /content/DATA/rawdata/ted2020/train.zh: 390062 sents, 9324801 tokens, 0.0% replaced by <unk>\n","2022-02-07 12:47:28 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 8000 types\n","2022-02-07 12:47:29 | INFO | fairseq_cli.preprocess | [zh] /content/DATA/rawdata/ted2020/valid.zh: 3940 sents, 93270 tokens, 0.00643% replaced by <unk>\n","2022-02-07 12:47:29 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 8000 types\n","2022-02-07 12:47:29 | INFO | fairseq_cli.preprocess | [zh] /content/DATA/rawdata/ted2020/test.zh: 4000 sents, 8000 tokens, 0.0% replaced by <unk>\n","2022-02-07 12:47:29 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to DATA/data-bin/ted2020\n"]}]},{"cell_type":"code","source":["config = Namespace(\n","    datadir = './DATA/data-bin/ted2020',\n","    savedir = './checkpoints/rnn',\n","    source_lang = 'en',\n","    target_lang = 'zh',\n","    num_workers= 2,\n","    max_tokens= 8192,\n","    accum_steps= 2,\n","    lr_factor= 2,\n","    lr_warmup= 4000,\n","    clip_norm= 1.0,\n","    max_epoch= 10, #30\n","    start_epoch= 1,\n","    beam= 5,\n","    max_len_a= 1.2,\n","    max_len_b= 10,\n","    post_process= 'sentencepiece',\n","    keep_last_epochs= 5,\n","    resume= None,\n","    use_wandb= False,\n",")"],"metadata":{"id":"1pbeMTt2J8zZ","executionInfo":{"status":"ok","timestamp":1644238074558,"user_tz":-480,"elapsed":404,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["logging.basicConfig(\n","    format= '%(asctime)s | %(levelname)s | %(name)s | %(message)s',\n","    datefmt= '%Y-%m-%d %H:%M:%S',\n","    level= 'INFO',\n","    stream= sys.stdout,\n",")\n","\n","proj = 'hw5.seq2seq'\n","logger = logging.getLogger(proj)\n","if config.use_wandb:\n","  import wandb\n","  wandb.init(project= proj, name= Path(config.savedir).stem, config= config)"],"metadata":{"id":"bBJEwiSmK59n","executionInfo":{"status":"ok","timestamp":1644238077366,"user_tz":-480,"elapsed":266,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["cuda_env = utils.CudaEnvironment()\n","utils.CudaEnvironment.pretty_print_cuda_env_list([cuda_env])\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SRFbaDGTL1IW","executionInfo":{"status":"ok","timestamp":1644238078909,"user_tz":-480,"elapsed":228,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"c09833a2-d9c2-4e31-eae6-1f93789e8342"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-02-07 12:47:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n","2022-02-07 12:47:58 | INFO | fairseq.utils | rank   0: capabilities =  3.7  ; total memory = 11.173 GB ; name = Tesla K80                               \n","2022-02-07 12:47:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n"]}]},{"cell_type":"code","source":["from fairseq.tasks.translation import TranslationConfig, TranslationTask\n","\n","task_cfg = TranslationConfig(\n","    data= config.datadir,\n","    source_lang= config.source_lang,\n","    target_lang= config.target_lang,\n","    train_subset= 'train',\n","    required_seq_len_multiple= 8,\n","    dataset_impl= 'mmap',\n","    upsample_primary= 1,\n",")\n","task = TranslationTask.setup_task(task_cfg)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L0o_M1WmMRqe","executionInfo":{"status":"ok","timestamp":1644238082775,"user_tz":-480,"elapsed":220,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"dc69f553-6c3b-4608-8667-fc6584867075"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-02-07 12:48:02 | INFO | fairseq.tasks.translation | [en] dictionary: 8000 types\n","2022-02-07 12:48:02 | INFO | fairseq.tasks.translation | [zh] dictionary: 8000 types\n"]}]},{"cell_type":"code","source":["logger.info('loading data for epoch 1')\n","task.load_dataset(split= 'train', epoch= 1, combine= True)\n","task.load_dataset(split= 'valid', epoch= 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wyy09ycSO-hv","executionInfo":{"status":"ok","timestamp":1644238084743,"user_tz":-480,"elapsed":235,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"1d8202c6-06e4-4041-d95c-9b2f69e82d20"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-02-07 12:48:04 | INFO | hw5.seq2seq | loading data for epoch 1\n","2022-02-07 12:48:04 | INFO | fairseq.data.data_utils | loaded 390,062 examples from: ./DATA/data-bin/ted2020/train.en-zh.en\n","2022-02-07 12:48:04 | INFO | fairseq.data.data_utils | loaded 390,062 examples from: ./DATA/data-bin/ted2020/train.en-zh.zh\n","2022-02-07 12:48:04 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 train en-zh 390062 examples\n","2022-02-07 12:48:04 | INFO | fairseq.data.data_utils | loaded 3,940 examples from: ./DATA/data-bin/ted2020/valid.en-zh.en\n","2022-02-07 12:48:04 | INFO | fairseq.data.data_utils | loaded 3,940 examples from: ./DATA/data-bin/ted2020/valid.en-zh.zh\n","2022-02-07 12:48:04 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 valid en-zh 3940 examples\n"]}]},{"cell_type":"code","source":["sample = task.dataset('valid')[1]\n","pprint.pprint(sample)\n","pprint.pprint(\n","    \"Source: \" + \\\n","    task.source_dictionary.string(\n","        sample['source'],\n","        config.post_process,\n","    )\n",")\n","pprint.pprint(\n","    'Target: ' + \\\n","    task.target_dictionary.string(\n","        sample['target'],\n","        config.post_process,\n","    )\n"," )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQK7UcTOPPl0","executionInfo":{"status":"ok","timestamp":1644238085915,"user_tz":-480,"elapsed":3,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"9b5012b4-5da2-4799-a406-d4e0b9268d41"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["{'id': 1,\n"," 'source': tensor([  23,   62,  187,  101,  340,  139,   31,   12,  294, 1739,   18,  408,\n","         210,  551,  112,  202,    5,  127,  971,  111, 1142,  646,  325,  441,\n","         221,   22,   11, 2091,  241,   14,   16,    7,    2]),\n"," 'target': tensor([   6, 1111, 1780,  153,  671,  465,  146, 2704, 1058, 1231,    9, 1781,\n","        1112, 2591,   42,   40,  674,    9,  606, 3268,  300,  463, 3470,    4,\n","         168,  553,  212,    2])}\n","('Source: you can exploit this to make sure that only some neurons contain our '\n"," \"lightactivated pore and others don't .\")\n","'Target: 你可以利用這個原理去令只有部分的神經細胞藏有我們設計的光驅動氣孔 ,而其他沒有'\n"]}]},{"cell_type":"code","source":["def load_data_iterator(task, split, epoch= 1, max_tokens= 4000, num_workers= 1, cached= True):\n","  batch_iterator = task.get_batch_iterator(\n","      dataset = task.dataset(split),\n","      max_tokens= max_tokens,\n","      max_sentences= None,\n","      max_positions= utils.resolve_max_positions(\n","          task.max_positions(),\n","          max_tokens,\n","      ),\n","      ignore_invalid_inputs= True,\n","      seed= seed,\n","      num_workers= num_workers,\n","      epoch= epoch,\n","      disable_iterator_cache= not cached,\n","  )\n","  return batch_iterator\n","\n","demo_epoch_obj = load_data_iterator(task, 'valid', epoch= 1, max_tokens= 20, num_workers= 1, cached= False)\n","demo_iter = demo_epoch_obj.next_epoch_itr(shuffle= True)\n","sample = next(demo_iter)\n","sample"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x2onvl4fP1kV","executionInfo":{"status":"ok","timestamp":1644238087895,"user_tz":-480,"elapsed":423,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"6f962be0-7572-4ee5-e95b-aba0da429077"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-02-07 12:48:07 | WARNING | fairseq.tasks.fairseq_task | 2,500 samples have invalid sizes and will be skipped, max_positions=(20, 20), first few sample ids=[546, 720, 1153, 3469, 2528, 2860, 223, 1114, 801, 2750]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'id': tensor([3761]),\n"," 'net_input': {'prev_output_tokens': tensor([[   2,  147,  427,   77,  161, 1526, 1912,  775,  395,    9,  367,    1,\n","              1,    1,    1,    1]]),\n","  'src_lengths': tensor([11]),\n","  'src_tokens': tensor([[   1,    1,    1,    1,    1,  457,   14,    5,   72,  368,   13,  473,\n","            164, 2405,    7,    2]])},\n"," 'nsentences': 1,\n"," 'ntokens': 11,\n"," 'target': tensor([[ 147,  427,   77,  161, 1526, 1912,  775,  395,    9,  367,    2,    1,\n","             1,    1,    1,    1]])}"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["from fairseq.models import(\n","    FairseqEncoder,\n","    FairseqIncrementalDecoder,\n","    FairseqEncoderDecoderModel\n",")"],"metadata":{"id":"inQkesJWbIZ6","executionInfo":{"status":"ok","timestamp":1644238089646,"user_tz":-480,"elapsed":241,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["class RNNEncoder(FairseqEncoder):\n","  def __init__(self, args, dictionary, embed_tokens):\n","    super().__init__(dictionary)\n","    self.embed_tokens = embed_tokens\n","\n","    self.embed_dim = args.encoder_embed_dim\n","    self.hidden_dim = args.encoder_ffn_embed_dim\n","    self.num_layers = args.encoder_layers\n","\n","    self.dropout_in_module = nn.Dropout(args.dropout)\n","    self.rnn = nn.GRU(\n","        self.embed_dim,\n","        self.hidden_dim,\n","        self.num_layers,\n","        dropout= args.dropout,\n","        batch_first= False,\n","        bidirectional=True\n","    )\n","    self.dropout_out_module = nn.Dropout(args.dropout)\n","\n","    self.padding_idx = dictionary.pad()\n","\n","  def combine_bider(self, outs, bsz: int):\n","    out = outs.view(self.num_layers, 2, bsz, -1).transpose(1, 2).contiguous()\n","    return out.view(self.num_layers, bsz, -1)\n","\n","  def forward(self, src_tokens, **unused):\n","    bsz, seqlen = src_tokens.size()\n","\n","    x = self.embed_tokens(src_tokens)\n","    x = self.dropout_in_module(x)\n","\n","    x =x.transpose(0, 1)\n","\n","    h0 = x.new_zeros(2 * self.num_layers, bsz, self.hidden_dim)\n","    x, final_hiddens = self.rnn(x, h0)\n","    outputs = self.dropout_out_module(x)\n","\n","    final_hiddens = self.combine_bider(final_hiddens, bsz)\n","\n","    encoder_padding_mask = src_tokens.eq(self.padding_idx).t()\n","    return tuple(\n","        (\n","            outputs,\n","            final_hiddens,\n","            encoder_padding_mask,\n","        )\n","    )\n","\n","  def recoder_encoder_out(self, encoder_out, new_order):\n","    return tuple(\n","        (\n","            encoder_out[0].index_select(1, new_order),\n","            encoder_out[1].index_select(1, new_order),\n","            encoder_out[2].index_select(1, new_order),\n","        )\n","    )\n"],"metadata":{"id":"Kv4VqWkkbk_P","executionInfo":{"status":"ok","timestamp":1644238090662,"user_tz":-480,"elapsed":1,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["class AttentionLayer(nn.Module):\n","  def __init__(self, input_embed_dim, source_embed_dim, output_embed_dim, bias= False):\n","    super().__init__()\n","\n","    self.input_proj = nn.Linear(input_embed_dim, source_embed_dim, bias= bias)\n","    self.output_proj = nn.Linear(\n","        input_embed_dim + source_embed_dim, output_embed_dim, bias= bias\n","    )\n","\n","  def forward(self, inputs, encoder_outputs, encoder_padding_mask):\n","    inputs = inputs.transpose(1, 0)\n","    encoder_outputs = encoder_outputs.transpose(1, 0)\n","    encoder_padding_mask = encoder_padding_mask.transpose(1, 0)\n","\n","    x = self.input_proj(inputs)\n","\n","    attn_scores = torch.bmm(x, encoder_outputs.transpose(1, 2))\n","\n","    if encoder_padding_mask is not None:\n","      encoder_padding_mask = encoder_padding_mask.unsqueeze(1)\n","      atten_scores = (\n","          attn_scores.float()\n","          .masked_fill_(encoder_padding_mask, float('-inf'))\n","          .type_as(attn_scores)\n","      )\n","\n","      attn_scores = F.softmax(attn_scores, dim= -1)\n","\n","      x = torch.bmm(attn_scores, encoder_outputs)\n","\n","      x = torch.cat((x, inputs), dim= -1)\n","      x = torch.tanh(self.output_proj(x))\n","\n","      return x.transpose(1, 0), attn_scores"],"metadata":{"id":"0ijrmF7DekyA","executionInfo":{"status":"ok","timestamp":1644238092945,"user_tz":-480,"elapsed":267,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["class RNNDecoder(FairseqIncrementalDecoder):\n","  def __init__(self, args, dictionary, embed_tokens):\n","    super().__init__(dictionary)\n","    self.embed_tokens = embed_tokens\n","\n","    assert args.decoder_layers == args.encoder_layers, f\"\"\"seq2seq rnn requires that encoder \n","    and decoder have same layers of rnn. got: {args.encoder_layers, args.decoder_layers}\"\"\"\n","    assert args.decoder_ffn_embed_dim == args.encoder_ffn_embed_dim*2, f\"\"\"seq2seq-rnn requires \n","    that decoder hidden to be 2*encoder hidden dim. got: {args.decoder_ffn_embed_dim, args.encoder_ffn_embed_dim*2}\"\"\" \n","\n","    self.embed_dim = args.decoder_embed_dim\n","    self.hidden_dim = args.decoder_ffn_embed_dim\n","    self.num_layers = args.decoder_layers\n","\n","    self.dropout_in_module = nn.Dropout(args.dropout)\n","    self.rnn = nn.GRU(\n","        self.embed_dim,\n","        self.hidden_dim,\n","        self.num_layers,\n","        dropout= args.dropout,\n","        batch_first= False,\n","        bidirectional= False\n","    )\n","    self.attention = AttentionLayer(\n","        self.embed_dim, self.hidden_dim, self.embed_dim, bias= False\n","        )\n","    self.dropout_out_module = nn.Dropout(args.dropout)\n","\n","    if self.hidden_dim != self.embed_dim:\n","      self.project_out_dim = nn.Linear(self.hidden_dim, self.embed_dim)\n","    else:\n","      self.project_out_dim = None\n","\n","    if args.share_decoder_input_output_embed:\n","      self.output_projection = nn.Linear(\n","          self.embed_tokens.weight.shape[1],\n","          self.embed_tokens.weight.shape[0],\n","          bias= False,\n","      )\n","      self.output_projection.weight = self.embed_tokens.weight\n","    else:\n","      self.output_projection = nn.Linear(\n","          self.output_embed_dim, mean= 0, std= self.output_embed_dim ** -0.5\n","      )\n","  def forward(self, prev_output_tokens, encoder_out, incremental_state= None, **unsed):\n","    encoder_outputs, encoder_hiddens, encoder_padding_mask = encoder_out\n","\n","    if incremental_state is not None and len(incremental_state) > 0:\n","      prev_output_tokens = prev_output_tokens[:, -1:]\n","      cache_state = self.get_incremental_state(incremental_state, 'cached_state')\n","      prev_hiddens = cache_state['prev_hiddens']\n","    else:\n","      prev_hiddens = encoder_hiddens\n","    \n","    bsz, seqlen = prev_output_tokens.size()\n","\n","    x = self.embed_tokens(prev_output_tokens)\n","    x = self.dropout_in_module(x)\n","\n","    x = x.transpose(0, 1)\n","\n","    if self.attention is not None:\n","      x, attn = self.attention(x, encoder_outputs, encoder_padding_mask)\n","\n","    x, final_hiddens = self.rnn(x, prev_hiddens)\n","    \n","    x = self.dropout_out_module(x)\n","\n","    if self.project_out_dim != None:\n","      x = self.project_out_dim(x)\n","\n","    x = self.output_projection(x)\n","\n","    x = x.transpose(1, 0)\n","\n","    cache_state = {\n","        'prev_hiddens': final_hiddens,\n","    }\n","    self.set_incremental_state(incremental_state, 'cached_state', cache_state)\n","\n","    return x, None\n","\n","  def recoder_incremental_state(\n","      self,\n","      incremental_state,\n","      new_order,\n","  ):\n","\n","    cache_state = self.get_incremental_state(incremental_state, 'cached_state')\n","    prev_hiddens = cache_state['prev_hiddens']\n","    prev_hiddens = [p.index_select(0, new_order) for p in prev_hiddens]\n","    cache_state = {\n","        'prev_hiddens': torch.stack(prev_hiddens),\n","    }\n","    self.set_incremental_state(incremental_state, 'cached_state', cache_state)\n","    return"],"metadata":{"id":"6RFoESQXJFuj","executionInfo":{"status":"ok","timestamp":1644238094201,"user_tz":-480,"elapsed":1,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["class Seq2Seq(FairseqEncoderDecoderModel):\n","  def __init__(self, args, encoder, decoder):\n","    super().__init__(encoder, decoder)\n","    self.args = args\n","\n","  def forward(\n","      self,\n","      src_tokens,\n","      src_lengths,\n","      prev_output_tokens,\n","      return_all_hiddens: bool = True,\n","  ):\n","\n","    encoder_out = self.encoder(\n","        src_tokens, src_lengths= src_lengths, return_all_hiddens= return_all_hiddens\n","\n","    )\n","    logits, extra = self.decoder(\n","        prev_output_tokens,\n","        encoder_out= encoder_out,\n","        src_lengths = src_lengths,\n","        return_all_hiddens= return_all_hiddens,\n","    )\n","    return logits, extra"],"metadata":{"id":"8u4bDZlDSCiT","executionInfo":{"status":"ok","timestamp":1644238096911,"user_tz":-480,"elapsed":1,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["def build_model(args, task):\n","  src_dict, tgt_dict = task.source_dictionary, task.target_dictionary\n","\n","  encoder_embed_tokens = nn.Embedding(len(src_dict), args.encoder_embed_dim, src_dict.pad())\n","  decoder_embed_tokens = nn.Embedding(len(tgt_dict), args.decoder_embed_dim, tgt_dict.pad())\n","\n","  encoder = RNNEncoder(args, src_dict, encoder_embed_tokens)\n","  decoder = RNNDecoder(args, tgt_dict, decoder_embed_tokens)\n","\n","  model = Seq2Seq(args, encoder, decoder)\n","\n","  def init_params(module):\n","    from fairseq.modules import MultiheadAttention\n","    if isinstance(module, nn.Linear):\n","      module.weight.data.normal_(mean= 0.0, std= 0.02)\n","      if module.bias is not None:\n","        module.bias.data.zero_()\n","    if isinstance(module, nn.Embedding):\n","      module.weight.data.normal_(mean= 0.0, std= 0.02)\n","      if module.padding_idx is not None:\n","        module.weight.data[module.padding_idx].zero_()\n","    if isinstance(module, MultiheadAttention):\n","      module.q_proj.weight.data.normal_(mean= 0.0, std= 0.02)\n","      module.k_proj.weight.data.normal_(mean= 0.0, std= 0.02)\n","      module.v_proj.weight.data.normal_(mean= 0.0, std= 0.02)\n","    if isinstance(module, nn.RNNBase):\n","      for name, param in module.named_parameters():\n","        if 'weight' in name or 'bias' in name:\n","          param.data.uniform_(-0.1, 0.1)\n","    \n","  model.apply(init_params)\n","  return model  "],"metadata":{"id":"HTUrKoVZT-LR","executionInfo":{"status":"ok","timestamp":1644238098503,"user_tz":-480,"elapsed":236,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["arch_args = Namespace(\n","    encoder_embed_dim= 256,\n","    encoder_ffn_embed_dim= 512,\n","    encoder_layers= 1,\n","    decoder_embed_dim= 256,\n","    decoder_ffn_embed_dim= 1024,\n","    decoder_layers= 1,\n","    share_decoder_input_output_embed= True,\n","    dropout= 0.3,\n",")"],"metadata":{"id":"bggpGr99Z8LG","executionInfo":{"status":"ok","timestamp":1644238100416,"user_tz":-480,"elapsed":270,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["if config.use_wandb:\n","  wandb.config.update(vars(arch_args))"],"metadata":{"id":"8ZnotlwuayQx","executionInfo":{"status":"ok","timestamp":1644238101388,"user_tz":-480,"elapsed":2,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["model = build_model(arch_args, task)\n","logger.info(model)"],"metadata":{"id":"jjOaApFKa7WW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644238102907,"user_tz":-480,"elapsed":418,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"b1d1d693-2730-4add-e41b-211a998a08c6"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]},{"output_type":"stream","name":"stdout","text":["2022-02-07 12:48:22 | INFO | hw5.seq2seq | Seq2Seq(\n","  (encoder): RNNEncoder(\n","    (embed_tokens): Embedding(8000, 256, padding_idx=1)\n","    (dropout_in_module): Dropout(p=0.3, inplace=False)\n","    (rnn): GRU(256, 512, dropout=0.3, bidirectional=True)\n","    (dropout_out_module): Dropout(p=0.3, inplace=False)\n","  )\n","  (decoder): RNNDecoder(\n","    (embed_tokens): Embedding(8000, 256, padding_idx=1)\n","    (dropout_in_module): Dropout(p=0.3, inplace=False)\n","    (rnn): GRU(256, 1024, dropout=0.3)\n","    (attention): AttentionLayer(\n","      (input_proj): Linear(in_features=256, out_features=1024, bias=False)\n","      (output_proj): Linear(in_features=1280, out_features=256, bias=False)\n","    )\n","    (dropout_out_module): Dropout(p=0.3, inplace=False)\n","    (project_out_dim): Linear(in_features=1024, out_features=256, bias=True)\n","    (output_projection): Linear(in_features=256, out_features=8000, bias=False)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["class LabelSmoothedCrossEntropyCriterion(nn.Module):\n","  def __init__(self, smoothing, ignore_index= None, reduce= True):\n","    super().__init__()\n","    self.smoothing = smoothing\n","    self.ignore_index = ignore_index\n","    self.reduce = reduce\n","\n","  def forward(self, lprobs, target):\n","    if target.dim() == lprobs.dim() - 1:\n","      target = target.unsqueeze(-1)\n","    nll_loss = -lprobs.gather(dim=-1, index=target)\n","    smooth_loss = -lprobs.sum(dim= -1, keepdim= True)\n","    if self.ignore_index is not None:\n","      pad_mask = target.eq(self.ignore_index)\n","      nll_loss.masked_fill_(pad_mask, 0.0)\n","      smooth_loss.masked_fill_(pad_mask, 0.0)\n","    else:\n","      nll_loss = nll_loss.squeeze(-1)\n","      smooth_loss = smooth_loss.squeeze(-1)\n","    if self.reduce:\n","      nll_loss = nll_loss.sum()\n","      smooth_loss = smooth_loss.sum()\n","\n","    eps_i = self.smoothing / lprobs.size(-1)\n","    loss = (1.0 - self.smoothing) * nll_loss + eps_i * smooth_loss\n","    return loss\n","\n","criterion = LabelSmoothedCrossEntropyCriterion(\n","    smoothing= 0.1,\n","    ignore_index = task.target_dictionary.pad(),\n",")\n"],"metadata":{"id":"bkCVSynbbOuO","executionInfo":{"status":"ok","timestamp":1644238104903,"user_tz":-480,"elapsed":235,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["class NoamOpt:\n","    \"Optim wrapper that implements rate.\"\n","    def __init__(self, model_size, factor, warmup, optimizer):\n","        self.optimizer = optimizer\n","        self._step = 0\n","        self.warmup = warmup\n","        self.factor = factor\n","        self.model_size = model_size\n","        self._rate = 0\n","    \n","    @property\n","    def param_groups(self):\n","        return self.optimizer.param_groups\n","        \n","    def multiply_grads(self, c):\n","        \"\"\"Multiplies grads by a constant *c*.\"\"\"                \n","        for group in self.param_groups:\n","            for p in group['params']:\n","                if p.grad is not None:\n","                    p.grad.data.mul_(c)\n","        \n","    def step(self):\n","        \"Update parameters and rate\"\n","        self._step += 1\n","        rate = self.rate()\n","        for p in self.param_groups:\n","            p['lr'] = rate\n","        self._rate = rate\n","        self.optimizer.step()\n","        \n","    def rate(self, step = None):\n","        \"Implement `lrate` above\"\n","        if step is None:\n","            step = self._step\n","        return 0 if not step else self.factor * \\\n","            (self.model_size ** (-0.5) *\n","            min(step ** (-0.5), step * self.warmup ** (-1.5)))"],"metadata":{"id":"zarJBB9VNSYF","executionInfo":{"status":"ok","timestamp":1644238106743,"user_tz":-480,"elapsed":230,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["optimizer = NoamOpt(\n","    model_size = arch_args.encoder_embed_dim,\n","    factor = config.lr_factor,\n","    warmup = config.lr_warmup,\n","    optimizer = torch.optim.AdamW(model.parameters(), lr= 0, betas= (0.9, 0.98), eps= 1e-9, weight_decay= 0.0001))\n","plt.plot(np.arange(1, 100000), [optimizer.rate(i) for i in range(1, 100000)])\n","plt.legend([f'{optimizer.model_size}: {optimizer.warmup}'])\n","None"],"metadata":{"id":"mRzviF-GLQHw","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1644238108982,"user_tz":-480,"elapsed":728,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"1810d4f6-6b5c-4e7b-fa32-f0a9fe172a08"},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["from fairseq.data import iterators\n","from torch.cuda.amp import GradScaler, autocast\n","\n","def train_one_epoch(epoch_itr, model, task, criterion, optimizer, accum_steps= 1):\n","  itr = epoch_itr.next_epoch_itr(shuffle= True)\n","  itr = iterators.GroupedIterator(itr, accum_steps)\n","\n","  stats = {'loss': []}\n","  scaler = GradScaler()\n","\n","  model.train()\n","  progress = tqdm.tqdm(itr, desc= f'train epoch {epoch_itr.epoch}', leave= False)\n","  for samples in progress:\n","    model.zero_grad()\n","    accum_loss = 0\n","    sample_size = 0\n","    for i, sample in enumerate(samples):\n","      if i == 1:\n","        torch.cuda.empty_cache()\n","\n","      sample = utils.move_to_cuda(sample, device= device)\n","      target = sample['target']\n","      sample_size_i = sample['ntokens']\n","      sample_size += sample_size_i\n","\n","      with autocast():\n","        net_output = model.forward(**sample['net_input'])\n","        lprobs = F.log_softmax(net_output[0], -1)\n","        loss = criterion(lprobs.view(-1, lprobs.size(-1)), target.view(-1))\n","\n","        accum_loss += loss.item()\n","        scaler.scale(loss).backward()\n","\n","    scaler.unscale_(optimizer)\n","    optimizer.multiply_grads(1 / (sample_size or 1.0))\n","    gnorm = nn.utils.clip_grad_norm_(model.parameters(), config.clip_norm)\n","\n","    scaler.step(optimizer)\n","    scaler.update()\n","\n","    loss_print = accum_loss / sample_size\n","    stats['loss'].append(loss_print)\n","    progress.set_postfix(loss= loss_print)\n","    if config.use_wandb:\n","      wandb.log({\n","          'train/loss': loss_print,\n","          'train/grad_norm': gnorm.item(),\n","          'train/lr': optimizer.rate(),\n","          'train/sample_size': sample_size,\n","      })\n","  loss_print = np.mean(stats['loss'])\n","  logger.info(f'training loss: {loss_print:.4f}')\n","  return stats"],"metadata":{"id":"utqwmKsIMR1e","executionInfo":{"status":"ok","timestamp":1644238110158,"user_tz":-480,"elapsed":1,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["sequence_generator = task.build_generator([model], config)\n","\n","\n","def decode(toks, dictionary):\n","  s = dictionary.string(\n","      toks.int().cpu(),\n","      config.post_process,\n","  )\n","  return s if s else '<unk>'\n","\n","def inference_step(sample, model):\n","    gen_out = sequence_generator.generate([model], sample)\n","    srcs = []\n","    hyps = []\n","    refs = []\n","    for i in range(len(gen_out)):\n","      srcs.append(decode(\n","          utils.strip_pad(sample[\"net_input\"][\"src_tokens\"][i], task.source_dictionary.pad()),\n","          task.source_dictionary,\n","      ))\n","      hyps.append(decode(\n","          gen_out[i][0][\"tokens\"],\n","          task.target_dictionary,\n","      ))\n","      refs.append(decode(\n","          utils.strip_pad(sample[\"target\"][i], task.target_dictionary.pad()),\n","          task.target_dictionary,\n","      ))\n","    return srcs, hyps, refs"],"metadata":{"id":"yb5oUAQYN0iJ","executionInfo":{"status":"ok","timestamp":1644238112300,"user_tz":-480,"elapsed":222,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["import shutil\n","import sacrebleu\n","\n","def validate(model, task, criterion, log_to_wandb= True):\n","  logger.info('begin validation')\n","  itr = load_data_iterator(task, 'valid', 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle= False)\n","\n","  stats = {'loss': [], 'bleu': 0, 'srcs': [], 'hyps': [], 'refs': []}\n","  srcs = []\n","  hyps = []\n","  refs = []\n","\n","  model.eval()\n","  progress = tqdm.tqdm(itr, desc = f'validation', leave= False)\n","  with torch.no_grad():\n","    for i, sample in enumerate(progress):\n","      sample = utils.move_to_cuda(sample, device= device)\n","      net_output = model.forward(**sample['net_input'])\n","\n","      lprobs = F.log_softmax(net_output[0], -1)\n","      target = sample['target']\n","      sample_size = sample['ntokens']\n","      loss = criterion(lprobs.view(-1, lprobs.size(-1)), target.view(-1)) / sample_size\n","      progress.set_postfix(valid_loss= loss.item())\n","      stats['loss'].append(loss)\n","\n","      s, h, r = inference_step(sample, model)\n","      srcs.extend(s)\n","      hyps.extend(h)\n","      refs.extend(r)\n","\n","  tok = 'zh' if task.cfg.target_lang == 'zh' else '13a'\n","  stats['loss'] = torch.stack(stats['loss']).mean().item()\n","  stats['bleu'] = sacrebleu.corpus_bleu(hyps, [refs], tokenize= tok)\n","  stats['srcs'] = srcs\n","  stats['hyps'] = hyps\n","  stats['refs'] = refs\n","\n","  if config.use_wandb and log_to_wandb:\n","    wandb.log({\n","        'valid/loss': stats['loss'],\n","        'valid/bleu': stats['bleu'].score,\n","    }, commit= False)\n","\n","  showid = np.random.randint(len(hyps))\n","  logger.info('example source: ' + srcs[showid])\n","  logger.info('example hypothesis: ' + hyps[showid])\n","  logger.info('example reference: ' + refs[showid])\n","\n","  logger.info(f\"validation loss:\\t{stats['loss']:.4f}\")\n","  logger.info(stats['bleu'].format())\n","  return stats"],"metadata":{"id":"BNInAelbSwOP","executionInfo":{"status":"ok","timestamp":1644238114145,"user_tz":-480,"elapsed":251,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["def validate_and_save(model, task, criterion, optimizer, epoch, save= True):\n","  stats = validate(model, task, criterion)\n","  bleu = stats['bleu']\n","  loss = stats['loss']\n","\n","  if save:\n","    savedir = Path(config.savedir).absolute()\n","    savedir.mkdir(parents= True, exist_ok= True)\n","\n","    check = {\n","        'model': model.state_dict(),\n","        \"stats\": {\"bleu\": bleu.score, \"loss\": loss},\n","        'optim': {'step': optimizer._step}\n","    }\n","    torch.save(check, savedir/f'checkpoint{epoch}.pt')\n","    shutil.copy(savedir/f'checkpoint{epoch}.pt', savedir/f'checkpoint_last.pt')\n","    logger.info(f'saved epoch checkpoint: {savedir}/checkpoint{epoch}.pt')\n","\n","    with open(savedir/f'samples{epoch}.{config.source_lang}-{config.target_lang}.txt', 'w') as f:\n","      for s, h in zip(stats['srcs'], stats['hyps']):\n","        f.write(f'{s}\\t{h}\\n')\n","\n","    if getattr(validate_and_save, 'best_bleu', 0) < bleu.score:\n","      validate_and_save.best_bleu = bleu.score\n","      torch.save(check, savedir/f'checkpoint_best.pt')\n","\n","    del_file = savedir / f'checkpoint{epoch - config.keep_last_epochs}.pt'\n","    if del_file.exists():\n","      del_file.unlink()\n","\n","  return stats\n","\n","def try_load_checkpoint(model, optimizer= None, name= None):\n","  name = name if name else 'checkpoint_last.pt'\n","  checkpath = Path(config.savedir)/ name\n","  if checkpath.exists():\n","    check = torch.load(checkpath)\n","    model.load_state_dict(check[\"model\"])\n","    stats = check['stats']\n","    step = 'unknown'\n","    if optimizer != None:\n","      optimizer._step = step = check['optim']['step']\n","    logger.info(f\"loaded checkpoint {checkpath}: step={step} loss={stats['loss']} bleu={stats['bleu']}\")\n","  else:\n","    logger.info(f'no checkpoints found at {checkpath}!')"],"metadata":{"id":"lSOlOmXRcxsp","executionInfo":{"status":"ok","timestamp":1644238115613,"user_tz":-480,"elapsed":243,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["model = model.to(device = device)\n","criterion = criterion.to(device)"],"metadata":{"id":"N7XJl_9XgOI0","executionInfo":{"status":"ok","timestamp":1644238127338,"user_tz":-480,"elapsed":10317,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"FTyTqFkJiNgH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644238129005,"user_tz":-480,"elapsed":230,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"8c53a55f-0841-427d-dad5-3439f79277c2"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Feb  7 12:48:48 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    57W / 149W |    585MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["logger.info('task:{}'.format(task.__class__.__name__))\n","logger.info('encoder: {}'.format(model.encoder.__class__.__name__))\n","logger.info('decoder: {}'.format(model.decoder.__class__.__name__))\n","logger.info('criterion: {}'.format(criterion.__class__.__name__))\n","logger.info('optimizer: {}'.format(optimizer.__class__.__name__))\n","logger.info(\n","    'num. model params: {:,} (num. trained: {:,})'.format(\n","        sum(p.numel() for p in model.parameters()),\n","        sum(p.numel() for p in model.parameters() if p.requires_grad),                          \n","    )\n",")\n","logger.info(f'max tokens per batch = {config.max_tokens}, accumulate steps = {config.accum_steps}')"],"metadata":{"id":"FLSY5On6iQZo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644238131924,"user_tz":-480,"elapsed":224,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"8b09b3de-1a35-4ced-c466-f4ea33f383b6"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-02-07 12:48:51 | INFO | hw5.seq2seq | task:TranslationTask\n","2022-02-07 12:48:51 | INFO | hw5.seq2seq | encoder: RNNEncoder\n","2022-02-07 12:48:51 | INFO | hw5.seq2seq | decoder: RNNDecoder\n","2022-02-07 12:48:51 | INFO | hw5.seq2seq | criterion: LabelSmoothedCrossEntropyCriterion\n","2022-02-07 12:48:51 | INFO | hw5.seq2seq | optimizer: NoamOpt\n","2022-02-07 12:48:51 | INFO | hw5.seq2seq | num. model params: 11,251,968 (num. trained: 11,251,968)\n","2022-02-07 12:48:51 | INFO | hw5.seq2seq | max tokens per batch = 8192, accumulate steps = 2\n"]}]},{"cell_type":"code","source":["epoch_itr = load_data_iterator(task, \"train\", config.start_epoch, config.max_tokens, config.num_workers)\n","try_load_checkpoint(model, optimizer, name=config.resume)\n","while epoch_itr.next_epoch_idx <= config.max_epoch:\n","    # train for one epoch\n","    train_one_epoch(epoch_itr, model, task, criterion, optimizer, config.accum_steps)\n","    stats = validate_and_save(model, task, criterion, optimizer, epoch=epoch_itr.epoch)\n","    logger.info(\"end of epoch {}\".format(epoch_itr.epoch))    \n","    epoch_itr = load_data_iterator(task, \"train\", epoch_itr.next_epoch_idx, config.max_tokens, config.num_workers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":576,"referenced_widgets":["1de96091c38f4b259a77d8a119161920","860ed7d6da024eb1a413321a3e025642","585e4b1c43224f33ba022b0fe3873fda","c8d6641edc25417396006ff4c963c823","e1bc046b06e14f1ea7381be6669a6fc4","aa69470e3eb341ab88a0055953ff54a5","179945ff35274a57bd7d09f12aeaff06","329c729bfebc4fd0abb297329498f2ea","698e893fce3048869a6afa576826bbe8","93dd6a019c0a48a98ac3ef1440a298f0","8cda8aa7f47c4745a0b4ff720d8d0e31","490efaddc7454c2eaf962836635eac1e","6be68187e89247b8a18d8d17032f7f08","34afd702f70c4ad68d0b28490e9586ed","9219aaaa7f8e4065a356028d56c2ff0e","bc1f81fed1064b719a28572973208c0d","b55c5935ce4145c88df3ceda73543fc3","479a66174c4142b49563e049dc7d4a37","51b03c066cbc433bae18e57184b1d1e8","6e0f18d280bf48de9daccec572927023","60debec359a24cbca32799ed6a935269","a86407264aff4821a3ba11475e93ad9b"]},"id":"Pci_hBuM9ynh","outputId":"24aa1be1-3af6-4505-98ba-f039a0e46771","executionInfo":{"status":"error","timestamp":1644239084187,"user_tz":-480,"elapsed":949105,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}}},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-02-07 12:48:55 | WARNING | fairseq.tasks.fairseq_task | 1 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[326703]\n","2022-02-07 12:48:55 | INFO | hw5.seq2seq | no checkpoints found at checkpoints/rnn/checkpoint_last.pt!\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1de96091c38f4b259a77d8a119161920","version_minor":0,"version_major":2},"text/plain":["train epoch 1:   0%|          | 0/787 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["2022-02-07 13:04:43 | INFO | hw5.seq2seq | training loss: 7.1388\n","2022-02-07 13:04:43 | INFO | hw5.seq2seq | begin validation\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"490efaddc7454c2eaf962836635eac1e","version_minor":0,"version_major":2},"text/plain":["validation:   0%|          | 0/22 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"error","ename":"NotImplementedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-fe682ee74cf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_itr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_itr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"end of epoch {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_itr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mepoch_itr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_itr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_epoch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-40-f5aac4543ec6>\u001b[0m in \u001b[0;36mvalidate_and_save\u001b[0;34m(model, task, criterion, optimizer, epoch, save)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bleu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-39-52e8390732bb>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, task, criterion, log_to_wandb)\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m       \u001b[0msrcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mhyps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-38-37da63f3eb5c>\u001b[0m in \u001b[0;36minference_step\u001b[0;34m(sample, model)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minference_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgen_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0msrcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mhyps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, models, sample, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \"\"\"\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     def _generate(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, sample, prefix_tokens, constraints, bos_token)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mnew_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mnew_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mencoder_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_encoder_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;31m# ensure encoder_outs is a List.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mencoder_outs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py\u001b[0m in \u001b[0;36mreorder_encoder_out\u001b[0;34m(self, encoder_outs, new_order)\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mencoder_outs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m             new_outs.append(\n\u001b[0;32m--> 842\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_encoder_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m             )\n\u001b[1;32m    844\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_outs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fairseq/models/fairseq_encoder.py\u001b[0m in \u001b[0;36mreorder_encoder_out\u001b[0;34m(self, encoder_out, new_order)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mencoder_out\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mrearranged\u001b[0m \u001b[0maccording\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mnew_order\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmax_positions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotImplementedError\u001b[0m: "]}]},{"cell_type":"code","source":["checkdir = config.savedir\n","!python ./fairseq/scripts/average_checkpoints.py \\\n","--inputs {checkdir} \\\n","--num-epoch-checkpoint 5 \\\n","--output {checkdir}/avg_last_5_checkpoint.pt"],"metadata":{"id":"Yhr24KnHkrIT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644221697555,"user_tz":-480,"elapsed":5468,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"2c6df035-dc0c-4a97-ebaf-1ede44617863"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(checkpoint_upper_bound=None, inputs=['./checkpoints/rnn'], num_epoch_checkpoints=5, num_update_checkpoints=None, output='./checkpoints/rnn/avg_last_5_checkpoint.pt')\n","Traceback (most recent call last):\n","  File \"./fairseq/scripts/average_checkpoints.py\", line 158, in <module>\n","    main()\n","  File \"./fairseq/scripts/average_checkpoints.py\", line 147, in main\n","    upper_bound=args.checkpoint_upper_bound,\n","  File \"./fairseq/scripts/average_checkpoints.py\", line 94, in last_n_checkpoints\n","    \"Found {} checkpoint files but need at least {}\", len(entries), n\n","Exception: ('Found {} checkpoint files but need at least {}', 1, 5)\n"]}]},{"cell_type":"code","source":["try_laod_checkpoint(model, name= 'avg_last_5_checkpoint.pt')\n","validate(model, task, criterion, log_to_wandb= False)\n","None"],"metadata":{"id":"BArN7o8_lBB-","colab":{"base_uri":"https://localhost:8080/","height":208},"executionInfo":{"status":"error","timestamp":1643638685665,"user_tz":-480,"elapsed":364,"user":{"displayName":"吳茂嘉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06774826719985339577"}},"outputId":"4eb4e767-33df-42e9-ddac-504b32c45720"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-70-356ac4b6f3ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtry_laod_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'avg_last_5_checkpoint.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_to_wandb\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'try_laod_checkpoint' is not defined"]}]},{"cell_type":"code","source":["def generate_prediction(model, task, split= 'test', outfile= './prediction.txt'):\n","  task.load_dataset(split= split, epoch= 1)\n","  itr = load_data_iterator(task, split, 1, config.max_tokens, condig.num_workers).next_epoch_itr(shuffle= False)\n","\n","  dixs = []\n","  hyps = []\n","\n","  model.eval()\n","  progress = tqdm.tqdm(itrm desc= f'prediction')\n","  with torch.no_grad():\n","    for i, sample in enumerate(progress):\n","      sample = utils.move_to_cuda(sample, device= device)\n","\n","      s, h, r = inference_step(sample, model)\n","\n","      hyps.extend(h)\n","      idxs.extend(list(sample['if']))\n","\n","  hyps = [x for _,x in sorted(zip(idxs, hyps))]\n","\n","  with open(outfile, 'w') as f:\n","    for h in hyps:\n","      f.write(h+'\\n')"],"metadata":{"id":"CuOjMvJ_lPRU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generate_prediction(model, task)"],"metadata":{"id":"UnpPUDbDma_b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["raise"],"metadata":{"id":"YIZZK5h2meRx"},"execution_count":null,"outputs":[]}]}