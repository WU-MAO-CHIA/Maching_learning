{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW3","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5d2782b7bd7348498c4016fed76bf51b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4ea04e02a84e435eaf7faf587eeb639a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b9425271941649eeb366fbfae6d3f6e7","IPY_MODEL_8d6a3a88b4b3475db56c3553874ebd89","IPY_MODEL_55e3e644d6364030994fd44046b725ff"]}},"4ea04e02a84e435eaf7faf587eeb639a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9425271941649eeb366fbfae6d3f6e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1a71352133254dc8ada180defc32ca56","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"  0%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_842c0035faab49b385ef7df884b19dfe"}},"8d6a3a88b4b3475db56c3553874ebd89":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e6d731f1c01f4956ba54d2fac7b0b0b7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":25,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d79396b1ef3244489a623e50c5ed3bc1"}},"55e3e644d6364030994fd44046b725ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cda41543775a4bc2908b8ddab072139a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/25 [00:12&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_68606690d35846cc9bc1cc270e40dad7"}},"1a71352133254dc8ada180defc32ca56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"842c0035faab49b385ef7df884b19dfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e6d731f1c01f4956ba54d2fac7b0b0b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d79396b1ef3244489a623e50c5ed3bc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cda41543775a4bc2908b8ddab072139a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"68606690d35846cc9bc1cc270e40dad7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7eec20beb1b24599a62f6ca8d69493c1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ff0d7eced35641cb89c1fb56c74d573e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_76867be52d7d4b688556e187fcb8c05a","IPY_MODEL_f894464383304a50aa97e8b51ebf5a77","IPY_MODEL_0206013786274648aa5fdac4560f8533"]}},"ff0d7eced35641cb89c1fb56c74d573e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"76867be52d7d4b688556e187fcb8c05a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0272253240a842fdb5e10566893e646a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c275313d7c7a4bd69f06e9634f61920d"}},"f894464383304a50aa97e8b51ebf5a77":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_48af114659eb4d2bb51785107e3d9153","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":27,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":27,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2047471c28c84c02a8696040ca39571d"}},"0206013786274648aa5fdac4560f8533":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_55e6e6988f4b44b4a5fd8ea2aba144f8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 27/27 [00:26&lt;00:00,  1.36it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5e58fd22769d48619dfbd760b8ad6795"}},"0272253240a842fdb5e10566893e646a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c275313d7c7a4bd69f06e9634f61920d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"48af114659eb4d2bb51785107e3d9153":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2047471c28c84c02a8696040ca39571d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"55e6e6988f4b44b4a5fd8ea2aba144f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5e58fd22769d48619dfbd760b8ad6795":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","source":["WH3 https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/HW03/HW03.ipynb#scrollTo=Y1c-GwrMQqMl"],"metadata":{"id":"UdtXIfbrXj4E"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"rpsM60Jf8XXG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b8zPRO9Wg2jk","outputId":"f9f88715-aa29-44c9-d751-62145a216dc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1awF7pZ9Dz7X1jn1_QAiKN-_v56veCEKy\n","To: /content/food-11.zip\n","100% 963M/963M [00:03<00:00, 254MB/s]\n","replace food-11/training/unlabeled/00/5176.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}],"source":["!gdown --id '1awF7pZ9Dz7X1jn1_QAiKN-_v56veCEKy' --output food-11.zip\n","\n","!unzip -q food-11.zip"]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from PIL import Image\n","from torch.utils.data import ConcatDataset, DataLoader, Subset\n","from torchvision.datasets import DatasetFolder\n","\n","from tqdm.auto import tqdm"],"metadata":{"id":"XSyN4ijahg8F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_tfm = transforms.Compose([transforms.Resize((128, 128)),\n","                                transforms.ColorJitter(0, 0, 0, 0)\n","                               # transforms.ToTensor(),\n","                              ])\n","\n","test_tfm = transforms.Compose([\n","                               transforms.Resize((128, 128)),\n","                               transforms.ToTensor(),\n","                              ])\n"],"metadata":{"id":"HE5Npy89iPig"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 128\n","\n","train_set = DatasetFolder('food-11/training/labeled', loader = lambda x: Image.open(x), extensions= 'jpg', transform= train_tfm)\n","valid_set = DatasetFolder('food-11/validation', loader= lambda x: Image.open(x), extensions= 'jpg', transform= test_tfm)\n","unlabeled_set = DatasetFolder('food-11/training/unlabeled', loader = lambda x: Image.open(x), extensions= 'jpg', transform= train_tfm)\n","test_set = DatasetFolder('food-11/testing', loader= lambda x: Image.open(x), extensions= 'jpg', transform= test_tfm)\n","\n","train_loader = DataLoader(train_set, batch_size= batch_size, shuffle= True, num_workers= 8, pin_memory= True)\n","valid_loader = DataLoader(valid_set, batch_size= batch_size, shuffle= True, num_workers= 8, pin_memory= True)\n","test_loader = DataLoader(test_set, batch_size= batch_size, shuffle= False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GJ1AGECbjBZj","executionInfo":{"status":"ok","timestamp":1642776053701,"user_tz":-480,"elapsed":268,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"ac17be11-000f-440b-8c9a-2c5187ffd6df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","source":["class Classifier(nn.Module):\n","  def __init__(self):\n","    super(Classifier, self).__init__()\n","    self.cnn_layers = nn.Sequential(\n","                                    nn.Conv2d(3, 64, 3, 1, 1),\n","                                    nn.BatchNorm2d(64),\n","                                    nn.ReLU(),\n","                                    nn.MaxPool2d(2, 2, 0),\n","\n","                                    nn.Conv2d(64, 128, 3, 1, 1),\n","                                    nn.BatchNorm2d(128),\n","                                    nn.ReLU(),\n","                                    nn.MaxPool2d(2, 2, 0),\n","\n","                                    nn.Conv2d(128, 256, 3, 1, 1),\n","                                    nn.BatchNorm2d(256),\n","                                    nn.ReLU(),\n","                                    nn.MaxPool2d(4, 4, 0)\n","                                   )\n","    self.fc.layers = nn.Sequential(\n","                                   nn.Linear(256 * 8 * 8, 256),\n","                                   nn.ReLU(),\n","                                   nn.Linear(256, 256),\n","                                   nn.ReLU(),\n","                                   nn.Linear(256, 11)\n","                                  )  \n","    def forward(self, x):\n","      x = self.cnn.layers(x)\n","      x = x.flatten(1)\n","      x = self.fc_layers(x)\n","\n","      return x"],"metadata":{"id":"FbJ7vnjomzuY"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y1c-GwrMQqMl"},"source":["class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","        # The arguments for commonly used modules:\n","        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n","        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n","\n","        # input image size: [3, 128, 128]\n","        self.cnn_layers = nn.Sequential(\n","            nn.Conv2d(3, 64, 3, 1, 1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","\n","            nn.Conv2d(64, 128, 3, 1, 1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),\n","\n","            nn.Conv2d(128, 256, 3, 1, 1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(4, 4, 0),\n","        )\n","        self.fc_layers = nn.Sequential(\n","            nn.Linear(256 * 8 * 8, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 11),\n","        )\n","\n","    def forward(self, x):\n","        # input (x): [batch_size, 3, 128, 128]\n","        # output: [batch_size, 11]\n","\n","        # Extract features by convolutional layers.\n","        x = self.cnn_layers(x)\n","\n","        # The extracted feature map must be flatten before going to fully-connected layers.\n","        x = x.flatten(1)\n","\n","        # The features are transformed by fully-connected layers to obtain the final logits.\n","        x = self.fc_layers(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_pseudo_labels(dataset, model, threshold= 0.65):\n","  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","  data_loader = DataLoader(dataset, batch_size= batch_size, shuffle = False)\n","  model.eval()\n","  softmax = nn.Softmax(dim= 1)\n","\n","  for batch in tqdm(data_loader):\n","    img, _ = batch\n","    with torch.no_grad():\n","      logits = model(img.to(device))\n","      probs = softmax(logits)\n","\n","  model.train()\n","  return dataset"],"metadata":{"id":"jKbN7_Bnm3V_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"," \n","model = Classifier().to(device)\n","model.device = device\n","\n","criterion = nn.CrossEntropyLoss()\n"," \n","optimizer = torch.optim.Adam(model.parameters(), lr= 0.0003, weight_decay= 1e-5)\n","\n","n_epochs = 10\n","\n","do_semi = False\n","\n","for epoch in range(n_epochs):\n","  if do_semi:\n","    pseudo_set = get_pseudo_labels(unlabeled_set, model)\n","\n","    concat_dataset = ConcatDataset([train_set, pseudo_set])\n","    train_loader = DataLoader(concat_dataset, batch_size= batch_size, shuffle= True, num_workers= 8, pin_memory= True)\n","\n","  model.train()\n","\n","  train_loss = []\n","  train_accs = []\n","\n","  for batch in tqdm(train_loader):\n","    imgs, labels = batch\n","    logits = model(imgs.to(device))\n","    loss = criterion(logits, labels.to(device))\n","    optimizer.zero_grad()\n","    loss.backward()\n","\n","    grad_norm = nn.utils.clip_grad_norm(model.parameters(), max_norm= 10)\n","    optimizer.step()\n","    acc = (logits.argmax(dim= -1) == labels.to(device)).float().mean()\n","\n","    train_loss.append(loss.item())\n","    train_accs.append(acc)\n","\n","  train_loss = sum(train_loss) / len(train_loss)\n","  train_acc = sum(train_accs) / len(train_accs)\n","\n","  print(f'[ Train | {epoch + 1:03d}/{n_epochs:03d}] loss = {train_loss:.5f}, acc = {train_acc:.5f}')\n","\n","  model.eval()\n","  \n","  valid_loss = []\n","  valid_accs = []\n","\n","  for batch in tqdm(valid_loader):\n","    imgs, labels = batch\n","\n","    with torch.no_grad():\n","      logits = model(imgs.to(device))\n","    \n","    loss = criterion(logits, labels.to(device))\n","    acc = (logits.argmax(dim= -1) == labels.to(device)).float().mean()\n","\n","    valid_loss.append(loss.item())\n","    valid_accs.append(acc)\n","\n","  valid_loss = sum(valid_loss) / len(valid_loss)\n","  valid_acc = sum(valid_accs) / len(valid_accs)\n","\n","  print(f'[ Valid | {epoch + 1:03d}/ {n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":781,"referenced_widgets":["5d2782b7bd7348498c4016fed76bf51b","4ea04e02a84e435eaf7faf587eeb639a","b9425271941649eeb366fbfae6d3f6e7","8d6a3a88b4b3475db56c3553874ebd89","55e3e644d6364030994fd44046b725ff","1a71352133254dc8ada180defc32ca56","842c0035faab49b385ef7df884b19dfe","e6d731f1c01f4956ba54d2fac7b0b0b7","d79396b1ef3244489a623e50c5ed3bc1","cda41543775a4bc2908b8ddab072139a","68606690d35846cc9bc1cc270e40dad7"]},"id":"jaFDG-OyuHhl","executionInfo":{"status":"error","timestamp":1642776073818,"user_tz":-480,"elapsed":12633,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"371c2090-46d2-41fa-91da-3ef3759e7db3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d2782b7bd7348498c4016fed76bf51b","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/25 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-4db6f859bab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mtrain_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 84, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 84, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 86, in default_collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>\n"]}]},{"cell_type":"code","source":["model.eval()\n","\n","predictions =[]\n","\n","for batch in tqdm(test_loader):\n","  imgs, labels = batch\n","\n","  with torch.no_grad():\n","    logits = model(imgs.to(device))\n","\n","    predictions.extend(logits.argmax(dim= -1).cpu().numpy().tolist())"],"metadata":{"id":"a7BcMRs-V9xG","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["7eec20beb1b24599a62f6ca8d69493c1","ff0d7eced35641cb89c1fb56c74d573e","76867be52d7d4b688556e187fcb8c05a","f894464383304a50aa97e8b51ebf5a77","0206013786274648aa5fdac4560f8533","0272253240a842fdb5e10566893e646a","c275313d7c7a4bd69f06e9634f61920d","48af114659eb4d2bb51785107e3d9153","2047471c28c84c02a8696040ca39571d","55e6e6988f4b44b4a5fd8ea2aba144f8","5e58fd22769d48619dfbd760b8ad6795"]},"executionInfo":{"status":"ok","timestamp":1642775702298,"user_tz":-480,"elapsed":26816,"user":{"displayName":"mark wu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04816660482965861860"}},"outputId":"fda12a3e-934b-43c6-c076-34c9ee36a9a1"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7eec20beb1b24599a62f6ca8d69493c1","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/27 [00:00<?, ?it/s]"]},"metadata":{}}]},{"cell_type":"code","source":["with open('predict.csv', 'w') as f:\n","  f.write('Id,Category\\n')\n","\n","  for i, pred in enumerate(predictions):\n","    f.write(f'{i}, {pred}\\n')"],"metadata":{"id":"vwrwPMiwWeOk"},"execution_count":null,"outputs":[]}]}